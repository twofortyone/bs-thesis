\section{RL Training Results}
The Service Restoration algorithm obtains the restoration plan through reinforcement learning training, 
as achieved in Chapter \ref{ch1}. Training scenario turns the network parameters into a Markov 
Decision Process, which defines the behavior and size of the algorithm operations.
Therefore, the numbers of lines and switches of the two test cases presented in Table \ref{ch2:tab:dn_data} are 
directly related to the number of states $n(S)$ and actions $n(A)$ presented in the following tables.

Additionally, Tables \ref{ch3:tab:td33}, \ref{ch3:tab:td123_1}, and \ref{ch3:tab:td123_2} show the 
elapsed time $T[min]$, the number of failures restored $n(FR)$, and the restoration rate $RR$ for each 
training relying on switch configurations in the IEEE 33 and the IEEE 123 Node Test Feeder.

\input{_chapter3/tab/td_33}
\input{_chapter3/tab/td_123_1}
\input{_chapter3/tab/td_123_2}
